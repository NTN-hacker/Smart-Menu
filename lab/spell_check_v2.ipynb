{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyvi import ViTokenizer\n",
    "from tqdm.contrib.concurrent import thread_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU SOJU</td>\n",
       "      <td>SOJU</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU VODKA</td>\n",
       "      <td>VODKA</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName VietnameseName EnglishName      Price\n",
       "0  001.jpeg        COMBO 1     COMBO 1     169000\n",
       "1  001.jpeg        COMBO 2     COMBO 2     169000\n",
       "2  001.jpeg        COMBO 3     COMBO 3     169000\n",
       "3  001.jpeg      RƯỢU SOJU        SOJU  NOT GIVEN\n",
       "4  001.jpeg     RƯỢU VODKA       VODKA  NOT GIVEN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data_sample/Data_Labeling.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15206</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>SÒ ĐIỆP NƯỚNG</td>\n",
       "      <td>GRILLED SCALLOP</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15207</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>KHÔ MỰC</td>\n",
       "      <td>DRIED SQUID</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ SƠN NƯỚNG</td>\n",
       "      <td>GRILLED CARDINAL FISH</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ CHỈ VÀNG</td>\n",
       "      <td>YELLOWSTRIPE SCAD</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ LAO NƯỚNG</td>\n",
       "      <td>GRILLED RED CORNETFISH</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ImageName VietnameseName             EnglishName      Price\n",
       "15206  850.jpeg  SÒ ĐIỆP NƯỚNG         GRILLED SCALLOP      10000\n",
       "15207  850.jpeg        KHÔ MỰC             DRIED SQUID  NOT GIVEN\n",
       "15208  850.jpeg   CÁ SƠN NƯỚNG   GRILLED CARDINAL FISH  NOT GIVEN\n",
       "15209  850.jpeg    CÁ CHỈ VÀNG       YELLOWSTRIPE SCAD      60000\n",
       "15210  850.jpeg  CÁ LAO NƯỚNG   GRILLED RED CORNETFISH      99000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Vietnamese food names\n",
    "food_names = df['VietnameseName'].values\n",
    "type(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'belgian dark ibu    phở đùi  trứng non mì trứng thành phố huế lòng đào'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text, remove punification number and etc\n",
    "import re\n",
    "\n",
    "def clean_food_name(food_name):\n",
    "    #Remove quantity for example 500ML 1L 20KG ....\n",
    "    food_name = re.sub(r'\\d+\\w+', '', food_name)\n",
    "    #Remove purification and digits\n",
    "    food_name = re.sub(r\"[^\\w\\s]|\\d\", '', food_name)\n",
    "    return food_name.lower().strip()\n",
    "\n",
    "test = clean_food_name('BELGIAN DARK 8.1%/IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON) mì trứng thành phố huế lòng đào')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belgian',\n",
       " 'dark',\n",
       " 'ibu',\n",
       " 'phở',\n",
       " 'đùi',\n",
       " 'trứng',\n",
       " 'non',\n",
       " 'mì',\n",
       " 'trứng',\n",
       " 'thành_phố',\n",
       " 'huế',\n",
       " 'lòng_đào']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bag_words(text):\n",
    "    tokens = ViTokenizer.tokenize(text).split(' ')\n",
    "    return [t.replace('_', '_') for t in tokens]\n",
    "\n",
    "get_bag_words(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15211/15211 [00:00<00:00, 338005.53it/s]\n",
      "100%|██████████| 15211/15211 [00:00<00:00, 316896.77it/s]\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = thread_map(clean_food_name, food_names, max_workers=6)\n",
    "food_vocabulary = thread_map(get_bag_words, food_vocabulary, max_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['combo', 'combo', 'combo', 'rượu', 'soju', 'rượu', 'vodka', 'tiger', 'lon', 'tiger']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = [item for sublist in food_vocabulary for item in sublist]\n",
    "print(food_vocabulary[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nướng', 1152),\n",
       " ('trà', 1140),\n",
       " ('bò', 951),\n",
       " ('xào', 809),\n",
       " ('chiên', 793),\n",
       " ('sữa', 765),\n",
       " ('gà', 712),\n",
       " ('cá', 619),\n",
       " ('tôm', 528),\n",
       " ('trứng', 505),\n",
       " ('hấp', 458),\n",
       " ('lẩu', 409),\n",
       " ('muối', 397),\n",
       " ('kem', 392),\n",
       " ('hải_sản', 372),\n",
       " ('cơm', 334),\n",
       " ('mực', 333),\n",
       " ('mì', 319),\n",
       " ('phô_mai', 315),\n",
       " ('chả', 310)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = Counter(food_vocabulary)\n",
    "corpus.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus\n",
    "with open('food_vocabulary_tokenize.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus.most_common():\n",
    "        save_format = f\"{food}${count}\\n\"\n",
    "        f.write(save_format)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell correct with symspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symspellpy\n",
    "import random\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_delete(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = random.randint(0, len(text_aggumented)-1)\n",
    "        del text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_replace(text, percent = 0.2):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "\n",
    "        char = random.choice(string.ascii_uppercase)\n",
    "        text_aggumented[k] = char\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_swap(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "        h = k\n",
    "        while h == k or text[h] == ' ':\n",
    "            h = random.randint(0, len(text)-1)\n",
    "        text_aggumented[k], text_aggumented[h] = text_aggumented[h], text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def lower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def random_text_aggument(text):\n",
    "    k = random.randint(0, 2)\n",
    "    random_agg = {0: random_delete, 1:random_replace, 2:random_swap}\n",
    "    return random_agg[k](text, percent=0.2)\n",
    "    \n",
    "test = random_text_aggument('BELGIAN DARK 8.1%IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON) thành pho')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 246375.94it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 250915.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cơm trắng', 'sụn gà chiên mắm', 'nộm hoa chuối', 'bò tơ xào nén', 'cóc lắc', 'kimbap chiên', 'salad rong nho']\n",
      "['cắm ơrtng', 'sụn à ciên m', 'nUm hoH Fhuối', 'Pò tơ xLo néJ', 'óc lc', 'kimbaR cQiên', 'ralag sonn dho']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_CASE = random.choices(food_names, k = 500)\n",
    "TEST_CASE = thread_map(lower, TEST_CASE, max_workers=6)\n",
    "TEST_CASE_WRONG = thread_map(random_text_aggument, TEST_CASE, max_workers=6)\n",
    "\n",
    "print(TEST_CASE[:7])\n",
    "print(TEST_CASE_WRONG[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cer(pred, true):\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "def wer(pred, true):\n",
    "    pred = pred.split()\n",
    "    true = true.split()\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "print(cer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\"))\n",
    "wer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nướng', 1152), ('trà', 1140), ('bò', 951), ('xào', 809), ('chiên', 793), ('sữa', 765), ('gà', 712), ('cá', 619), ('tôm', 528), ('trứng', 505), ('hấp', 458), ('lẩu', 409), ('muối', 397), ('kem', 392), ('hải_sản', 372), ('cơm', 334), ('mực', 333), ('mì', 319), ('phô_mai', 315), ('chả', 310)]\n"
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "EDIT_DISTANCE = 3\n",
    "\n",
    "spell_check = SymSpell(max_dictionary_edit_distance=EDIT_DISTANCE)\n",
    "spell_check.load_dictionary('food_vocabulary_tokenize.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "\n",
    "\n",
    "print(list(islice(spell_check.words.items(), 20)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spell(text):\n",
    "    import re \n",
    "    \n",
    "    text = re.sub(r'[.\\?#@+,<>%~`!$^&\\(\\):;\\\\\\/]', r' \\g<0> ', text)\n",
    "    \n",
    "    suggestion = spell_check.lookup_compound(text, max_edit_distance=EDIT_DISTANCE,\n",
    "                                             ignore_non_words=False, ignore_term_with_digits=False)\n",
    "    \n",
    "    return suggestion[0]._term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "['cơm trắng', 'sụn gà chiên mắm', 'nộm hoa chuối', 'bò tơ xào nén', 'cóc lắc', 'kimbap chiên', 'salad rong nho']\n",
      "['cắm ơrtng', 'sụn à ciên m', 'nUm hoH Fhuối', 'Pò tơ xLo néJ', 'óc lc', 'kimbaR cQiên', 'ralag sonn dho']\n",
      "['cơm trứng', 'sụn gà chiên m', 'nấm hoa chuối', 'bò tơ xào né', 'óc l', 'kimbap chiên', 'rang song kho']\n",
      "Metric: WER: 0.538 CER: 0.636\n",
      "CPU times: total: 750 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_result = []\n",
    "wer_result = []\n",
    "cer_result = []\n",
    "N = 7\n",
    "for test_case, val in zip(TEST_CASE_WRONG, TEST_CASE):\n",
    "    correct_text = correct_spell(test_case)\n",
    "    \n",
    "    test_result.append(correct_text)\n",
    "        \n",
    "        \n",
    "    wer_result.append(\n",
    "        wer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "    cer_result.append(\n",
    "        cer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "\n",
    "print(\"Example: \")\n",
    "print(TEST_CASE[:N])\n",
    "print(TEST_CASE_WRONG[:N])\n",
    "print(test_result[:N])\n",
    "\n",
    "print(\"Metric:\", f\"WER: {np.mean(wer_result):.3f}\", f\"CER: {np.mean(cer_result):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hoa sả'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_spell(\"hoi_sả\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('smart_menu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cca91d1f76e5abfdd07e2c17342a07bd112c752dc295866857041e010f5f929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
