{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.contrib.concurrent import thread_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU SOJU</td>\n",
       "      <td>SOJU</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU VODKA</td>\n",
       "      <td>VODKA</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName VietnameseName EnglishName      Price\n",
       "0  001.jpeg        COMBO 1     COMBO 1     169000\n",
       "1  001.jpeg        COMBO 2     COMBO 2     169000\n",
       "2  001.jpeg        COMBO 3     COMBO 3     169000\n",
       "3  001.jpeg      RƯỢU SOJU        SOJU  NOT GIVEN\n",
       "4  001.jpeg     RƯỢU VODKA       VODKA  NOT GIVEN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data_sample/Data_Labeling.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15206</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>SÒ ĐIỆP NƯỚNG</td>\n",
       "      <td>GRILLED SCALLOP</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15207</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>KHÔ MỰC</td>\n",
       "      <td>DRIED SQUID</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ SƠN NƯỚNG</td>\n",
       "      <td>GRILLED CARDINAL FISH</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ CHỈ VÀNG</td>\n",
       "      <td>YELLOWSTRIPE SCAD</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ LAO NƯỚNG</td>\n",
       "      <td>GRILLED RED CORNETFISH</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ImageName VietnameseName             EnglishName      Price\n",
       "15206  850.jpeg  SÒ ĐIỆP NƯỚNG         GRILLED SCALLOP      10000\n",
       "15207  850.jpeg        KHÔ MỰC             DRIED SQUID  NOT GIVEN\n",
       "15208  850.jpeg   CÁ SƠN NƯỚNG   GRILLED CARDINAL FISH  NOT GIVEN\n",
       "15209  850.jpeg    CÁ CHỈ VÀNG       YELLOWSTRIPE SCAD      60000\n",
       "15210  850.jpeg  CÁ LAO NƯỚNG   GRILLED RED CORNETFISH      99000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Vietnamese food names\n",
    "food_names = df['VietnameseName'].values\n",
    "type(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belgian', 'dark', 'ibu', 'phở', 'đùi', 'trứng', 'non']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text, remove punification number and etc\n",
    "import re\n",
    "\n",
    "def clean_food_name(food_name):\n",
    "    #Remove quantity for example 500ML 1L 20KG ....\n",
    "    food_name = re.sub(r'\\d+\\w+', '', food_name)\n",
    "    #Remove purification and digits\n",
    "    food_name = re.sub(r\"[^\\w\\s]|\\d\", '', food_name)\n",
    "    return food_name.lower().strip().split()\n",
    "\n",
    "test = clean_food_name('BELGIAN DARK 8.1%/IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON)')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['belgian dark', 'dark ibu', 'ibu phở', 'phở đùi', 'đùi trứng', 'trứng non', 'belgian dark ibu', 'dark ibu phở', 'ibu phở đùi', 'phở đùi trứng', 'đùi trứng non', 'belgian dark ibu phở', 'dark ibu phở đùi', 'ibu phở đùi trứng', 'phở đùi trứng non']\n"
     ]
    }
   ],
   "source": [
    "def get_big_gram(text, n=2, m=4):\n",
    "    words = clean_food_name(text)\n",
    "    big_grams = []\n",
    "    \n",
    "    for k in range(n,m+1):\n",
    "        for i in range(len(words)):\n",
    "            big_gram = ''\n",
    "            if i + k > len(words):\n",
    "                continue\n",
    "            \n",
    "            for j in range(k):\n",
    "                big_gram += words[i+j] + ' '\n",
    "                \n",
    "            big_grams.append(big_gram.strip())\n",
    "            \n",
    "    return big_grams\n",
    "\n",
    "print(get_big_gram('BELGIAN DARK 8.1%/IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON)'))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15211/15211 [00:00<00:00, 323559.99it/s]\n",
      "100%|██████████| 15211/15211 [00:00<00:00, 334116.57it/s]\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = thread_map(clean_food_name, food_names, max_workers=6)\n",
    "food_vocabulary_big_grams = thread_map(get_big_gram, food_names, max_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combo',\n",
       " 'combo',\n",
       " 'combo',\n",
       " 'rượu',\n",
       " 'soju',\n",
       " 'rượu',\n",
       " 'vodka',\n",
       " 'tiger',\n",
       " 'lon',\n",
       " 'tiger']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_vocabulary = [item for sublist in food_vocabulary for item in sublist]\n",
    "food_vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rượu soju', 'rượu vodka', 'tiger lon', 'tiger chai', 'tiger bạc', 'bạc chai', 'tiger bạc chai', 'tiger bạc', 'bạc lon', 'tiger bạc lon', 'bò húc', 'bia quy', 'quy nhơn', 'bia quy nhơn', 'bia bivina', 'strong bow', 'rau muống', 'muống xào', 'xào tỏi', 'rau muống xào']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary_big_grams = [item for sublist in food_vocabulary_big_grams for item in sublist]\n",
    "print(food_vocabulary_big_grams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cá', 1500),\n",
       " ('trà', 1310),\n",
       " ('nướng', 1157),\n",
       " ('sữa', 1114),\n",
       " ('chiên', 1052),\n",
       " ('bò', 1009),\n",
       " ('xào', 817),\n",
       " ('gà', 775),\n",
       " ('tôm', 706),\n",
       " ('cơm', 620)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = Counter(food_vocabulary)\n",
    "corpus.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trà sữa', 472),\n",
       " ('hải sản', 373),\n",
       " ('phô mai', 320),\n",
       " ('trân châu', 252),\n",
       " ('cơm chiên', 245),\n",
       " ('cá hồi', 240),\n",
       " ('sữa chua', 211),\n",
       " ('chiên mắm', 175),\n",
       " ('thập cẩm', 166),\n",
       " ('muối ớt', 159)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_big_grams = Counter(food_vocabulary_big_grams)\n",
    "corpus_big_grams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus\n",
    "with open('../postprocessing/food_vocabulary.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus.most_common():\n",
    "        save_format = f\"{food}${count}\\n\"\n",
    "        f.write(save_format)\n",
    "\n",
    "with open('../postprocessing/food_vocabulary_big_grams.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus_big_grams.most_common():\n",
    "        save_format = f\"{food}${count}\\n\"\n",
    "        f.write(save_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell correct with symspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symspellpy\n",
    "import random\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BELGIzN DARK 8.1%IBU 3e - 500ML (PyỞ ĐÙf n TRỨNj NnN)'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_delete(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = random.randint(0, len(text_aggumented)-1)\n",
    "        del text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_replace(text, percent = 0.2):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "\n",
    "        char = random.choice(string.ascii_lowercase)\n",
    "        text_aggumented[k] = char\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_swap(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "        h = k\n",
    "        while h == k or text[h] == ' ':\n",
    "            h = random.randint(0, len(text)-1)\n",
    "        text_aggumented[k], text_aggumented[h] = text_aggumented[h], text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def lower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def random_text_aggument(text):\n",
    "    #k = random.randint(2, 2)\n",
    "    k = 1\n",
    "    random_agg = {0: random_delete, 1:random_replace, 2:random_swap}\n",
    "    return random_agg[k](text, percent=0.15)\n",
    "    \n",
    "random_text_aggument('BELGIAN DARK 8.1%IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 166784.79it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 166427.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ốc hương xào me', 'cua bỏ lò phô mai', 'lịch huyết nướng giấy bạc', 'chình nướng muối ớt', 'phở trứng', 'ngọc dương hầm thuốc bắc', 'mì xào nấm chay']\n",
      "['xc hưvrg xào me', 'nua yỏ lò phô mai', 'lfmh hcyết nướnk giấy bạc', 'chìhh nưbng guối ớt', 'phở lrứng', 'ngọc yzơng hvm thuốc bắl', 'mì xào nwm yeay']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_CASE = random.choices(food_names, k = 500)\n",
    "TEST_CASE = thread_map(lower, TEST_CASE, max_workers=5)\n",
    "TEST_CASE_WRONG = thread_map(random_text_aggument, TEST_CASE, max_workers=6)\n",
    "\n",
    "print(TEST_CASE[:7])\n",
    "print(TEST_CASE_WRONG[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cer(pred, true):\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "def wer(pred, true):\n",
    "    pred = pred.split()\n",
    "    true = true.split()\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "print(cer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\"))\n",
    "wer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cá', 1500), ('trà', 1310), ('nướng', 1157), ('sữa', 1114), ('chiên', 1052)]\n",
      "[('trà sữa', 472), ('hải sản', 373), ('phô mai', 320), ('trân châu', 252), ('cơm chiên', 245)]\n"
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "EDIT_DISTANCE = 3\n",
    "\n",
    "spell_check = SymSpell(max_dictionary_edit_distance=EDIT_DISTANCE)\n",
    "spell_check.load_dictionary('../postprocessing/food_vocabulary.txt', 0, 1, \n",
    "                                    encoding='utf-8')\n",
    "spell_check.load_bigram_dictionary('../postprocessing/food_vocabulary_big_grams.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "\n",
    "print(list(islice(spell_check.words.items(), 5)))\n",
    "print(list(islice(spell_check.bigrams.items(), 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spell(text):\n",
    "    suggestion = spell_check.lookup_compound(text, max_edit_distance=EDIT_DISTANCE, ignore_non_words=True)\n",
    "    \n",
    "    return suggestion[0]._term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "['ốc hương xào me', 'cua bỏ lò phô mai', 'lịch huyết nướng giấy bạc', 'chình nướng muối ớt', 'phở trứng', 'ngọc dương hầm thuốc bắc', 'mì xào nấm chay']\n",
      "['xc hưvrg xào me', 'nua yỏ lò phô mai', 'lfmh hcyết nướnk giấy bạc', 'chìhh nưbng guối ớt', 'phở lrứng', 'ngọc yzơng hvm thuốc bắl', 'mì xào nwm yeay']\n",
      "['ốc hương xào me', 'cua đỏ lò phô mai', 'lạnh huyết nướng giấy bạc', 'chình nướng muối ớt', 'phở trứng', 'ngọc hương hầm thuốc bắp', 'mì xào nấm cay']\n",
      "Metric: WER: 0.410 CER: 0.790\n",
      "CPU times: total: 828 ms\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_result = []\n",
    "wer_result = []\n",
    "cer_result = []\n",
    "N = 7\n",
    "for test_case in TEST_CASE_WRONG:\n",
    "    correct_text = correct_spell(test_case)\n",
    "    \n",
    "    test_result.append(correct_text)\n",
    "        \n",
    "        \n",
    "    wer_result.append(\n",
    "        wer(correct_text, test_case)\n",
    "    )\n",
    "    \n",
    "    cer_result.append(\n",
    "        cer(correct_text, test_case)\n",
    "    )\n",
    "    \n",
    "\n",
    "print(\"Example: \")\n",
    "print(TEST_CASE[:N])\n",
    "print(TEST_CASE_WRONG[:N])\n",
    "print(test_result[:N])\n",
    "\n",
    "print(\"Metric:\", f\"WER: {np.mean(wer_result):.3f}\", f\"CER: {np.mean(cer_result):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('smart_menu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cca91d1f76e5abfdd07e2c17342a07bd112c752dc295866857041e010f5f929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
